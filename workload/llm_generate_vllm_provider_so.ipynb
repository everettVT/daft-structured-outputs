{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7cd01fc6",
      "metadata": {
        "id": "7cd01fc6"
      },
      "source": [
        "# Structured Outputs with llm_generate using the vLLM Provider\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/everettVT/daft-structured-outputs/blob/main/workload/llm_generate_vllm_provider_examples.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "Dont forget to follow installation and setup instructions in the readme.\n",
        "\n",
        "WARNING: vLLM has experimental support for macOS with Apple Silicon. For now, users must build from source to natively run on macOS.\n",
        "\n",
        "Colab or Intel/AMD Recommended for CPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install daft vllm pydantic"
      ],
      "metadata": {
        "id": "fHiuOCAu53a5"
      },
      "id": "fHiuOCAu53a5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "484f884f",
      "metadata": {
        "id": "484f884f"
      },
      "source": [
        "#### Authenticate with HuggingFace for Access to Gemma-3 Series models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b36d9c1d",
      "metadata": {
        "id": "b36d9c1d"
      },
      "outputs": [],
      "source": [
        "!hf auth login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62ff7777",
      "metadata": {
        "id": "62ff7777"
      },
      "outputs": [],
      "source": [
        "import daft\n",
        "from daft import col\n",
        "from daft.functions import llm_generate, format\n",
        "from vllm.sampling_params import GuidedDecodingParams\n",
        "\n",
        "MAX_TOKENS = 100\n",
        "TEMPERATURE = 0.0\n",
        "NUM_GPUS = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c46c0a98",
      "metadata": {
        "id": "c46c0a98"
      },
      "source": [
        "## Guided Choice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ebe47cb",
      "metadata": {
        "id": "5ebe47cb"
      },
      "outputs": [],
      "source": [
        "df_choice = daft.from_pydict({\n",
        "    \"text\": [\n",
        "        \"I'm not a fan of slow data pipelines\",\n",
        "        \"Daft Dataframes are wicked fast!\",\n",
        "    ]\n",
        "})\n",
        "\n",
        "df_choice = df_choice.with_column(\"sentiment\", llm_generate(\n",
        "    \"Classify this sentiment: \" + df_choice[\"text\"],\n",
        "    model=\"google/gemma-3-270m\",\n",
        "    provider=\"vllm\",\n",
        "    guided_decoding= GuidedDecodingParams(choice=[\"Positive\", \"Negative\"]),\n",
        "    max_tokens= MAX_TOKENS,\n",
        "    temperature= TEMPERATURE,\n",
        "    num_gpus= NUM_GPUS\n",
        ")).collect()\n",
        "df_choice.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69d3f699",
      "metadata": {
        "id": "69d3f699"
      },
      "source": [
        "## Guided Regex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae935c0c",
      "metadata": {
        "id": "ae935c0c"
      },
      "outputs": [],
      "source": [
        "df_regex = daft.from_pydict({\n",
        "    \"name\": [\n",
        "        \"John Doe\",\n",
        "        \"Jane Smith\",\n",
        "        \"Alice Johnson\",\n",
        "        \"Bob Brown\",\n",
        "        \"Charlie Davis\",\n",
        "    ],\n",
        "    \"company\": [\n",
        "        \"Acme Inc.\",\n",
        "        \"Globex Corp.\",\n",
        "        \"Initech\",\n",
        "        \"Soylent Corp.\",\n",
        "        \"Umbrella Corp.\",\n",
        "    ]\n",
        "})\n",
        "\n",
        "df_regex = df_regex.with_column(\"email\", llm_generate(\n",
        "    format(\"\"\"\n",
        "    Generate an email address for {} at {}\n",
        "    End in .com\n",
        "    \"\"\", col(\"name\"), col(\"company\")),\n",
        "    model=\"google/gemma-3-270m\",\n",
        "    provider=\"vllm\",\n",
        "    guided_decoding=GuidedDecodingParams(regex=r\"\\w+@\\w+\\.com\\n\"),\n",
        "    max_tokens=MAX_TOKENS,\n",
        "    temperature=TEMPERATURE,\n",
        "    num_gpus=NUM_GPUS\n",
        "))\n",
        "df_regex.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccb488f7",
      "metadata": {
        "id": "ccb488f7"
      },
      "source": [
        "## Guided Decoding by Pydantic JSON Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0c68505",
      "metadata": {
        "id": "f0c68505"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from enum import Enum\n",
        "\n",
        "class CarType(str, Enum):\n",
        "    sedan = \"sedan\"\n",
        "    suv = \"SUV\"\n",
        "    truck = \"Truck\"\n",
        "    coupe = \"Coupe\"\n",
        "\n",
        "\n",
        "class CarDescription(BaseModel):\n",
        "    make: str = Field(description=\"The make of the car\")\n",
        "    model: str = Field(description=\"The model name of the car\")\n",
        "    car_type: CarType = Field(description=\"The type of vehicle\")\n",
        "\n",
        "\n",
        "df_pydantic = daft.from_pydict({\n",
        "    \"decade\": [\n",
        "        \"80's\",\n",
        "        \"90's\",\n",
        "        \"2000's\",\n",
        "    ]\n",
        "})\n",
        "\n",
        "df_pydantic = df_pydantic.with_column(\"car_description_json\", llm_generate(\n",
        "    format(\"Generate a car description for the {} decade\", col(\"decade\")),\n",
        "    model=\"google/gemma-3-270m\",\n",
        "    provider=\"vllm\",\n",
        "    guided_decoding=GuidedDecodingParams(json=CarDescription.model_json_schema()),\n",
        "    max_tokens=MAX_TOKENS,\n",
        "    temperature=TEMPERATURE,\n",
        "    num_gpus=NUM_GPUS\n",
        "))\n",
        "\n",
        "df_pydantic = df_pydantic.with_column(\"car_description_validated\",\n",
        "    df_pydantic[\"car_description_json\"].apply(\n",
        "        lambda x: CarDescription.model_validate_json(x),\n",
        "        return_dtype= daft.DataType.python()\n",
        "    )\n",
        ")\n",
        "df_pydantic.show()\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71dbf56d",
      "metadata": {
        "id": "71dbf56d"
      },
      "source": [
        "## Guided Decoding by Grammar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0945cf04",
      "metadata": {
        "id": "0945cf04"
      },
      "outputs": [],
      "source": [
        "simplified_sql_grammar = \"\"\"\n",
        "root ::= select_statement\n",
        "select_statement ::= \"SELECT \" column \" from \" table \" where \" condition\n",
        "column ::= \"col_1 \" | \"col_2 \"\n",
        "table ::= \"table_1 \" | \"table_2 \"\n",
        "condition ::= column \"= \" number\n",
        "number ::= \"1 \" | \"2 \"\n",
        "limit ::= \"LIMIT \" number\n",
        "\"\"\"\n",
        "\n",
        "df_grammar = daft.from_pydict({\n",
        "    \"prompt\": [\n",
        "        \"Generate an SQL query to show the 'username' and 'email' from the 'users' table.\",\n",
        "        \"Generate an SQL query to show the 'name' and 'age' from the 'users' table where the age is greater than 30.\",\n",
        "        \"Generate an SQL query to show the 'name' and 'age' from the 'users' table where the age is greater than 30 and the name is 'John Doe'.\",\n",
        "        \"Show me the first 10 rows of the 'users' table.\",\n",
        "    ]\n",
        "})\n",
        "\n",
        "df_grammar = df_grammar.with_column(\"sql_query\", llm_generate(\n",
        "    df_grammar[\"prompt\"],\n",
        "    model=\"google/gemma-3-270m\",\n",
        "    provider=\"vllm\",\n",
        "    guided_decoding=GuidedDecodingParams(grammar=simplified_sql_grammar),\n",
        "    num_gpus=NUM_GPUS\n",
        "))\n",
        "df_grammar.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yfm6j_i0SsPQ"
      },
      "id": "yfm6j_i0SsPQ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}