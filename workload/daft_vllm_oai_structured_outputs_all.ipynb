{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f6f457a",
   "metadata": {},
   "source": [
    "# Daft llm_generate Structured Outputs Examples\n",
    "Example Suite for structured output calls over text for vLLM and SGLang OpenAI Compatible Servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f79f53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"daft[huggingface]\" vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4025f712",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hf auth login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b94de1d",
   "metadata": {},
   "source": [
    "### Online Serving - Launch vLLM OpenAI Compatible Server\n",
    "\n",
    "Run the following in your terminal\n",
    "```bash\n",
    " python -m vllm.entrypoints.openai.api_server \\\n",
    "  --model google/gemma-3n-e4b-it \\\n",
    "  --guided-decoding-backend guidance \\\n",
    "  --dtype bfloat16 \\\n",
    "  --gpu-memory-utilization 0.85 \\\n",
    "  --host 0.0.0.0 --port 8000\n",
    "```\n",
    "\n",
    "Note: If you are in Google Colab, you can open a terminal by clicking the terminal icon in the bottom left of the ui.\n",
    "\n",
    "It usually takes at least **7.5** minutes before the vLLM server is ready\n",
    "\n",
    "For these small examples, an L4 GPU should be fine. T4 doesn't support bfloat16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2264862",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. **Text Examples with llm_generate**\n",
    "    - Simple Text Generation\n",
    "    - Guided Choice\n",
    "    - Guided Regex\n",
    "    - Pydantic Json Schema\n",
    "    - Guided Grammar\n",
    "    - Structural Tag\n",
    "\n",
    "2. **Image Examples with Batch UDF**\n",
    "    - "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff3c351",
   "metadata": {},
   "source": [
    "## Text Examples with llm_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651430d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import daft\n",
    "from daft import col\n",
    "from daft.functions import llm_generate\n",
    "\n",
    "api_key = \"none\"\n",
    "base_url = \"https://localhost:8000\"\n",
    "model_id = \"google/gemma-3n-e4b-it\"\n",
    "sampling_params = {\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_new_tokens\": 200,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addba710",
   "metadata": {},
   "source": [
    "### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09a6914",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = daft.from_pylist([\n",
    "    {\"text\":\"What is the best thing about daft dataframes?\"},\n",
    "])\n",
    "\n",
    "df_result = df.with_column(\"result\", llm_generate(\n",
    "        df[\"text\"],\n",
    "        model=model_id,\n",
    "        provider=\"openai\",\n",
    "        base_url=base_url, \n",
    "        api_key=api_key\n",
    "    )\n",
    ")\n",
    "df_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78106580",
   "metadata": {},
   "source": [
    "### Guided Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027697fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = daft.from_pylist([\n",
    "    {\"text\":\"Classify this sentiment: Daft is fast!\"},\n",
    "])\n",
    "\n",
    "df_result = df.with_column(\"result\", llm_generate(\n",
    "        df[\"text\"],\n",
    "        model=model_id,\n",
    "        provider=\"openai\",\n",
    "        extra_body={\"guided_choice\": [\"positive\", \"negative\"]},\n",
    "        base_url=base_url, \n",
    "        api_key=api_key\n",
    "    )\n",
    ")\n",
    "df_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5927fb2c",
   "metadata": {},
   "source": [
    "### Guided Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f325b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = daft.from_pylist([\n",
    "    {\"text\":\"Generate an email address for Alan Turing, who works at Enigma. End in .com and new line. Example result: 'alan.turing@enigma.com\\n'\"},\n",
    "])\n",
    "\n",
    "df_result = df.with_column(\"result\", llm_generate(\n",
    "        df[\"text\"],\n",
    "        model=model_id,\n",
    "        provider=\"openai\",\n",
    "        extra_body={\"guided_regex\": r\"[a-z0-9.]{1,20}@\\w{6,10}\\.com\\n\"},\n",
    "        base_url=base_url,\n",
    "        api_key=api_key\n",
    "    )\n",
    ")\n",
    "df_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4853954a",
   "metadata": {},
   "source": [
    "### Pydantic Json Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971cff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import pydantic\n",
    "\n",
    "# Define the pydantic model\n",
    "class CarType(str, enum.Enum):\n",
    "    SEDAN = \"SEDAN\"\n",
    "    SUV = \"SUV\"\n",
    "    TRUCK = \"TRUCK\"\n",
    "    COUPE = \"COUPE\"\n",
    "\n",
    "\n",
    "class CarDescription(pydantic.BaseModel):\n",
    "    brand: str\n",
    "    model: str\n",
    "    car_type: CarType\n",
    "\n",
    "# Define the prompt\n",
    "df = daft.from_pylist([\n",
    "    {\"text\": \"Generate a JSON with the brand, model and car_type of the most iconic car from the 90's\"},\n",
    "])\n",
    "\n",
    "# Generate the result\n",
    "df_result = df.with_column(\"result\", llm_generate(\n",
    "        df[\"text\"],\n",
    "        model=model_id,\n",
    "        provider=\"openai\",\n",
    "        response_format = {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\n",
    "                \"name\": \"car-description\",\n",
    "                \"schema\": CarDescription.model_json_schema(),\n",
    "            },\n",
    "        },\n",
    "        base_url=base_url,\n",
    "        api_key=api_key\n",
    "    )\n",
    ")\n",
    "\n",
    "# Validate the result, return a pydantic model\n",
    "df_result_validated = df_result.with_column(\"pydantic_model_validated\", df_result[\"result\"].apply(\n",
    "    lambda x: CarDescription.model_validate_json(x),\n",
    "    return_dtype= daft.DataType.python()\n",
    "))\n",
    "\n",
    "df_result_validated.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f324d4",
   "metadata": {},
   "source": [
    "### Guided Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d408cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = daft.from_pylist([\n",
    "    {\"text\":\"Generate an SQL query to show the 'username' and 'email'from the 'users' table.\"},\n",
    "])\n",
    "\n",
    "df_result = df.with_column(\"result\", llm_generate(\n",
    "        df[\"text\"],\n",
    "        model=model_id,\n",
    "        provider=\"openai\",\n",
    "        extra_body={\"guided_grammar\": \"\"\"\n",
    "root ::= select_statement\n",
    "\n",
    "select_statement ::= \"SELECT \" column \" from \" table \" where \" condition\n",
    "\n",
    "column ::= \"col_1 \" | \"col_2 \"\n",
    "\n",
    "table ::= \"table_1 \" | \"table_2 \"\n",
    "\n",
    "condition ::= column \"= \" number\n",
    "\n",
    "number ::= \"1 \" | \"2 \"\n",
    "        \"\"\"},\n",
    "        base_url=base_url,\n",
    "        api_key=api_key\n",
    "    )\n",
    ")\n",
    "df_result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f367b5fe",
   "metadata": {},
   "source": [
    "### Structural Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a22246",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = daft.from_pylist([\n",
    "    {\"text\": \"\"\"\n",
    "You have access to the following function to retrieve the weather in a city:\n",
    "\n",
    "{\n",
    "    \"name\": \"get_weather\",\n",
    "    \"parameters\": {\n",
    "        \"city\": {\n",
    "            \"param_type\": \"string\",\n",
    "            \"description\": \"The city to get the weather for\",\n",
    "            \"required\": True\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "If a you choose to call a function ONLY reply in the following format:\n",
    "<{start_tag}={function_name}>{parameters}{end_tag}\n",
    "where\n",
    "\n",
    "start_tag => `<function`\n",
    "parameters => a JSON dict with the function argument name as key and function\n",
    "              argument value as value.\n",
    "end_tag => `</function>`\n",
    "\n",
    "Here is an example,\n",
    "<function=example_function_name>{\"example_name\": \"example_value\"}</function>\n",
    "\n",
    "Reminder:\n",
    "- Function calls MUST follow the specified format\n",
    "- Required parameters MUST be specified\n",
    "- Only call one function at a time\n",
    "- Put the entire function call reply on one line\n",
    "- Always add your sources when using search results to answer the user query\n",
    "\n",
    "You are a helpful assistant.\n",
    "\n",
    "Given the previous instructions, what is the weather in New York City, Boston,\n",
    "and San Francisco?\"\"\"},\n",
    "])\n",
    "\n",
    "# Generate the result\n",
    "df_result = df.with_column(\"result\", llm_generate(\n",
    "        df[\"text\"],\n",
    "        model=model_id,\n",
    "        provider=\"openai\",\n",
    "        response_format = {\n",
    "            \"type\": \"structural_tag\",\n",
    "            \"structures\": [\n",
    "                {\n",
    "                    \"begin\": \"<function=get_weather>\",\n",
    "                    \"schema\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\"city\": {\"type\": \"string\"}},\n",
    "                        \"required\": [\"city\"],\n",
    "                    },\n",
    "                    \"end\": \"</function>\",\n",
    "                }\n",
    "            ],\n",
    "            \"triggers\": [\"<function=\"],\n",
    "        },\n",
    "        base_url=base_url,\n",
    "        api_key=api_key\n",
    "    )\n",
    ")\n",
    "df_result.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
