{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cd01fc6",
   "metadata": {},
   "source": [
    "# Structured Outputs with llm_generate using the vLLM Provider\n",
    "\n",
    "Dont forget to follow installation and setup instructions in the readme.\n",
    "\n",
    "WARNING: vLLM has experimental support for macOS with Apple Silicon. For now, users must build from source to natively run on macOS.\n",
    "\n",
    "Colab or Intel/AMD Recommended for CPU. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484f884f",
   "metadata": {},
   "source": [
    "#### Authenticate with HuggingFace for Access to Gemma-3 Series models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36d9c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hf auth login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ff7777",
   "metadata": {},
   "outputs": [],
   "source": [
    "import daft\n",
    "from daft import col\n",
    "from daft.functions import llm_generate, format\n",
    "from vllm.sampling_params import GuidedDecodingParams\n",
    "\n",
    "MAX_TOKENS = 100\n",
    "TEMPERATURE = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46c0a98",
   "metadata": {},
   "source": [
    "## Guided Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ebe47cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                          d\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error when running pipeline node UDF _vLLMGenerator\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Actor Pool UDF unexpectedly failed with traceback:\nTraceback (most recent call last):\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/daft/execution/udf_worker.py\", line 48, in udf_event_loop\n    initialized_projection = ExpressionsProjection([e._initialize_udfs() for e in uninitialized_projection])\n                                                    ^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/daft/expressions/expressions.py\", line 1952, in _initialize_udfs\n    return Expression._from_pyexpr(initialize_udfs(self._expr))\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/daft/udf/legacy.py\", line 41, in initialize\n    return self.inner(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/daft/functions/llm.py\", line 110, in __init__\n    from vllm import LLM\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/vllm/__init__.py\", line 13, in <module>\n    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/vllm/engine/arg_utils.py\", line 22, in <module>\n    from vllm.config import (BlockSize, CacheConfig, CacheDType, CompilationConfig,\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/vllm/config.py\", line 43, in <module>\n    from vllm.transformers_utils.config import (\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/vllm/transformers_utils/config.py\", line 33, in <module>\n    from vllm.transformers_utils.configs import (ChatGLMConfig, Cohere2Config,\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/vllm/transformers_utils/configs/__init__.py\", line 28, in <module>\n    from vllm.transformers_utils.configs.ovis import OvisConfig\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/vllm/transformers_utils/configs/ovis.py\", line 76, in <module>\n    AutoConfig.register(\"aimv2\", AIMv2Config)\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py\", line 1312, in register\n    CONFIG_MAPPING.register(model_type, config, exist_ok=exist_ok)\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py\", line 999, in register\n    raise ValueError(f\"'{key}' is already used by a Transformers config, pick another name.\")\n\nValueError: 'aimv2' is already used by a Transformers config, pick another name.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m      1\u001b[39m df_choice = daft.from_pydict({\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m      3\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mI\u001b[39m\u001b[33m'\u001b[39m\u001b[33mm not a fan of slow data pipelines\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      4\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mDaft Dataframes are wicked fast!\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      5\u001b[39m     ]\n\u001b[32m      6\u001b[39m })\n\u001b[32m      8\u001b[39m df_choice = \u001b[43mdf_choice\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_column\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msentiment\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mClassify this sentiment: \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_choice\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#model=\"google/gemma-3-270m\",\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvllm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#guided_decoding=GuidedDecodingParams(choice=[\"Positive\", \"Negative\"]),\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMAX_TOKENS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTEMPERATURE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m df_choice.show()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/daft/dataframe/dataframe.py:3968\u001b[39m, in \u001b[36mDataFrame.collect\u001b[39m\u001b[34m(self, num_preview_rows)\u001b[39m\n\u001b[32m   3937\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Executes the entire DataFrame and materializes the results.\u001b[39;00m\n\u001b[32m   3938\u001b[39m \n\u001b[32m   3939\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3965\u001b[39m \u001b[33;03m    (Showing first 3 of 3 rows)\u001b[39;00m\n\u001b[32m   3966\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3967\u001b[39m \u001b[38;5;28mself\u001b[39m._broadcast_query_plan()\n\u001b[32m-> \u001b[39m\u001b[32m3968\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_materialize_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3969\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3970\u001b[39m dataframe_len = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/daft/dataframe/dataframe.py:3930\u001b[39m, in \u001b[36mDataFrame._materialize_results\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3928\u001b[39m context = get_context()\n\u001b[32m   3929\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3930\u001b[39m     \u001b[38;5;28mself\u001b[39m._result_cache = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_or_create_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_builder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3931\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._result\n\u001b[32m   3932\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/daft/runners/native_runner.py:66\u001b[39m, in \u001b[36mNativeRunner.run\u001b[39m\u001b[34m(self, builder)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, builder: LogicalPlanBuilder) -> PartitionCacheEntry:\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     results = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuilder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     result_pset = LocalPartitionSet()\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/daft/runners/native_runner.py:99\u001b[39m, in \u001b[36mNativeRunner.run_iter\u001b[39m\u001b[34m(self, builder, results_buffer_size)\u001b[39m\n\u001b[32m     92\u001b[39m executor = NativeExecutor()\n\u001b[32m     93\u001b[39m results_gen = executor.run(\n\u001b[32m     94\u001b[39m     plan,\n\u001b[32m     95\u001b[39m     {k: v.values() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._part_set_cache.get_all_partition_sets().items()},\n\u001b[32m     96\u001b[39m     daft_execution_config,\n\u001b[32m     97\u001b[39m     results_buffer_size,\n\u001b[32m     98\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m results_gen\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/daft/execution/native_executor.py:44\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdaft\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunners\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpartitioning\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LocalMaterializedResult\n\u001b[32m     39\u001b[39m psets_mp = {\n\u001b[32m     40\u001b[39m     part_id: [part.micropartition()._micropartition \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m parts] \u001b[38;5;28;01mfor\u001b[39;00m part_id, parts \u001b[38;5;129;01min\u001b[39;00m psets.items()\n\u001b[32m     41\u001b[39m }\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mLocalMaterializedResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMicroPartition\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_from_pymicropartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpart\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_executor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_physical_plan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpsets_mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdaft_execution_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresults_buffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/daft/execution/udf.py:124\u001b[39m, in \u001b[36mUdfHandle.eval_input\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UDFException(response[\u001b[32m1\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbase_exc\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response[\u001b[32m0\u001b[39m] == _ERROR:\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mActor Pool UDF unexpectedly failed with traceback:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(response[\u001b[32m1\u001b[39m].format()))\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response[\u001b[32m0\u001b[39m] == _SUCCESS:\n\u001b[32m    126\u001b[39m     out_name, out_size = response[\u001b[32m1\u001b[39m], response[\u001b[32m2\u001b[39m]\n",
      "\u001b[31mRuntimeError\u001b[39m: Actor Pool UDF unexpectedly failed with traceback:\nTraceback (most recent call last):\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/daft/execution/udf_worker.py\", line 48, in udf_event_loop\n    initialized_projection = ExpressionsProjection([e._initialize_udfs() for e in uninitialized_projection])\n                                                    ^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/daft/expressions/expressions.py\", line 1952, in _initialize_udfs\n    return Expression._from_pyexpr(initialize_udfs(self._expr))\n                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/daft/udf/legacy.py\", line 41, in initialize\n    return self.inner(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/daft/functions/llm.py\", line 110, in __init__\n    from vllm import LLM\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/vllm/__init__.py\", line 13, in <module>\n    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/vllm/engine/arg_utils.py\", line 22, in <module>\n    from vllm.config import (BlockSize, CacheConfig, CacheDType, CompilationConfig,\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/vllm/config.py\", line 43, in <module>\n    from vllm.transformers_utils.config import (\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/vllm/transformers_utils/config.py\", line 33, in <module>\n    from vllm.transformers_utils.configs import (ChatGLMConfig, Cohere2Config,\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/vllm/transformers_utils/configs/__init__.py\", line 28, in <module>\n    from vllm.transformers_utils.configs.ovis import OvisConfig\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/vllm/transformers_utils/configs/ovis.py\", line 76, in <module>\n    AutoConfig.register(\"aimv2\", AIMv2Config)\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py\", line 1312, in register\n    CONFIG_MAPPING.register(model_type, config, exist_ok=exist_ok)\n\n  File \"/Users/everett-founder/git/ugh/daft-structured-outputs/.venv/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py\", line 999, in register\n    raise ValueError(f\"'{key}' is already used by a Transformers config, pick another name.\")\n\nValueError: 'aimv2' is already used by a Transformers config, pick another name.\n"
     ]
    }
   ],
   "source": [
    "df_choice = daft.from_pydict({\n",
    "    \"text\": [\n",
    "        \"I'm not a fan of slow data pipelines\",\n",
    "        \"Daft Dataframes are wicked fast!\",\n",
    "    ]\n",
    "})\n",
    "\n",
    "df_choice = df_choice.with_column(\"sentiment\", llm_generate(\n",
    "    \"Classify this sentiment: \" + df_choice[\"text\"],\n",
    "    #model=\"google/gemma-3-270m\",\n",
    "    provider=\"vllm\",\n",
    "    #guided_decoding=GuidedDecodingParams(choice=[\"Positive\", \"Negative\"]),\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    temperature=TEMPERATURE,\n",
    ")).collect()\n",
    "df_choice.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d3f699",
   "metadata": {},
   "source": [
    "## Guided Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae935c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regex = daft.from_pydict({\n",
    "    \"name\": [\n",
    "        \"John Doe\",\n",
    "        \"Jane Smith\",\n",
    "        \"Alice Johnson\",\n",
    "        \"Bob Brown\",\n",
    "        \"Charlie Davis\",\n",
    "    ],\n",
    "    \"company\": [\n",
    "        \"Acme Inc.\",\n",
    "        \"Globex Corp.\",\n",
    "        \"Initech\",\n",
    "        \"Soylent Corp.\",\n",
    "        \"Umbrella Corp.\",\n",
    "    ]\n",
    "}) \n",
    "\n",
    "df_regex = df_regex.with_column(\"email\", llm_generate(\n",
    "    format(\"\"\"\n",
    "    Generate an email address for {} at {}\n",
    "    End in .com and new line.\n",
    "    Example result:\n",
    "    alan.turing@enigma.com\n",
    "    \"\"\", col[\"name\"], col[\"company\"]),\n",
    "    model=\"google/gemma-3-270m\",\n",
    "    provider=\"vllm\",\n",
    "    guided_decoding=GuidedDecodingParams(regex=r\"\\w+@\\w+\\.com\\n\"),\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    temperature=TEMPERATURE,\n",
    "))\n",
    "df_regex.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb488f7",
   "metadata": {},
   "source": [
    "## Guided Decoding by Pydantic JSON Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c68505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from enum import Enum\n",
    "\n",
    "class CarType(str, Enum):\n",
    "    sedan = \"sedan\"\n",
    "    suv = \"SUV\"\n",
    "    truck = \"Truck\"\n",
    "    coupe = \"Coupe\"\n",
    "\n",
    "\n",
    "class CarDescription(BaseModel):\n",
    "    brand: str\n",
    "    model: str\n",
    "    car_type: CarType\n",
    "\n",
    "\n",
    "df_pydantic = daft.from_pydict({\n",
    "    \"decade\": [\n",
    "        \"80's\",\n",
    "        \"90's\",\n",
    "        \"2000's\",\n",
    "    ]\n",
    "})\n",
    "\n",
    "df_pydantic = df_pydantic.with_column(\"car_description_json\", llm_generate(\n",
    "    format(\"Generate a car description for the {} decade\", col[\"decade\"]),\n",
    "    model=\"google/gemma-3-270m\",\n",
    "    provider=\"vllm\",\n",
    "    guided_decoding=GuidedDecodingParams(json=CarDescription.model_json_schema()),\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    temperature=TEMPERATURE,\n",
    "))\n",
    "\n",
    "df_pydantic = df_pydantic.with_column(\"car_description_validated\", \n",
    "    df_pydantic[\"car_description_json\"].apply(\n",
    "        lambda x: CarDescription.model_validate_json(x),\n",
    "        return_dtype= daft.DataType.python()\n",
    "    )\n",
    ")\n",
    "df_pydantic.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dbf56d",
   "metadata": {},
   "source": [
    "## Guided Decoding by Grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0945cf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_sql_grammar = \"\"\"\n",
    "root ::= select_statement\n",
    "select_statement ::= \"SELECT \" column \" from \" table \" where \" condition\n",
    "column ::= \"col_1 \" | \"col_2 \"\n",
    "table ::= \"table_1 \" | \"table_2 \"\n",
    "condition ::= column \"= \" number\n",
    "number ::= \"1 \" | \"2 \"\n",
    "limit ::= \"LIMIT \" number\n",
    "\"\"\"\n",
    "\n",
    "df_grammar = daft.from_pydict({\n",
    "    \"prompt\": [\n",
    "        \"Generate an SQL query to show the 'username' and 'email' from the 'users' table.\",\n",
    "        \"Generate an SQL query to show the 'name' and 'age' from the 'users' table where the age is greater than 30.\",\n",
    "        \"Generate an SQL query to show the 'name' and 'age' from the 'users' table where the age is greater than 30 and the name is 'John Doe'.\",\n",
    "        \"Show me how to see the first 10 rows of the 'users' table.\",\n",
    "    ]\n",
    "})\n",
    "\n",
    "df_grammar = df_grammar.with_column(\"sql_query\", llm_generate(\n",
    "    df_grammar[\"prompt\"],\n",
    "    model=\"google/gemma-3-270m\",\n",
    "    provider=\"vllm\",\n",
    "    guided_decoding=GuidedDecodingParams(grammar=simplified_sql_grammar),\n",
    "))\n",
    "df_grammar.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
